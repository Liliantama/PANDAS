{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TIME SERIES (GETTING FINANCIAL DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Create your time range (start and end variables). The start date should be 01/01/2015 and the end should today (whatever your today is)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2024-07-07', '2024-07-08', '2024-07-09', '2024-07-10',\n",
      "               '2024-07-11', '2024-07-12', '2024-07-13', '2024-07-14',\n",
      "               '2024-07-15', '2024-07-16'],\n",
      "              dtype='datetime64[ns]', length=3485, freq='D')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '2015-01-01'\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')  # today's date in 'YYYY-MM-DD' format\n",
    "\n",
    "# Create the date range\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "# Display the date range\n",
    "print(date_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Select the Apple, Tesla, Twitter, IBM, LinkedIn stocks symbols and assign them to a variable called stocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL', 'TSLA', 'TWTR', 'IBM', 'LNKD']\n"
     ]
    }
   ],
   "source": [
    "# Define the stock symbols\n",
    "stocks = ['AAPL', 'TSLA', 'TWTR', 'IBM', 'LNKD']\n",
    "\n",
    "# Display the stocks variable\n",
    "print(stocks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Read the data from google, assign to df and print it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.40-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.0.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting lxml>=4.9.1 (from yfinance)\n",
      "  Using cached lxml-5.2.2-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (4.2.2)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2024.1)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Downloading frozendict-2.4.4-py312-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.17.6.tar.gz (3.0 MB)\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/3.0 MB 2.0 MB/s eta 0:00:02\n",
      "     - -------------------------------------- 0.1/3.0 MB 845.5 kB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.1/3.0 MB 1.1 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.2/3.0 MB 857.5 kB/s eta 0:00:04\n",
      "     -- ------------------------------------- 0.2/3.0 MB 857.5 kB/s eta 0:00:04\n",
      "     -- ------------------------------------- 0.2/3.0 MB 857.5 kB/s eta 0:00:04\n",
      "     -- ------------------------------------- 0.2/3.0 MB 857.5 kB/s eta 0:00:04\n",
      "     --- ------------------------------------ 0.2/3.0 MB 577.6 kB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 0.3/3.0 MB 703.0 kB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 0.3/3.0 MB 675.8 kB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 0.4/3.0 MB 713.5 kB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 0.4/3.0 MB 713.5 kB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 0.4/3.0 MB 713.5 kB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 0.4/3.0 MB 596.2 kB/s eta 0:00:05\n",
      "     ------ --------------------------------- 0.5/3.0 MB 627.8 kB/s eta 0:00:04\n",
      "     ------ --------------------------------- 0.5/3.0 MB 630.4 kB/s eta 0:00:04\n",
      "     ------- -------------------------------- 0.5/3.0 MB 643.2 kB/s eta 0:00:04\n",
      "     ------- -------------------------------- 0.5/3.0 MB 643.2 kB/s eta 0:00:04\n",
      "     ------- -------------------------------- 0.5/3.0 MB 643.2 kB/s eta 0:00:04\n",
      "     -------- ------------------------------- 0.6/3.0 MB 593.2 kB/s eta 0:00:04\n",
      "     --------- ------------------------------ 0.7/3.0 MB 655.8 kB/s eta 0:00:04\n",
      "     --------- ------------------------------ 0.7/3.0 MB 655.4 kB/s eta 0:00:04\n",
      "     --------- ------------------------------ 0.7/3.0 MB 655.4 kB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 0.8/3.0 MB 655.4 kB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 0.8/3.0 MB 647.3 kB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 0.8/3.0 MB 647.5 kB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 0.9/3.0 MB 648.1 kB/s eta 0:00:04\n",
      "     ------------ --------------------------- 0.9/3.0 MB 648.3 kB/s eta 0:00:04\n",
      "     ------------ --------------------------- 0.9/3.0 MB 641.4 kB/s eta 0:00:04\n",
      "     ------------- -------------------------- 1.0/3.0 MB 648.7 kB/s eta 0:00:04\n",
      "     ------------- -------------------------- 1.0/3.0 MB 642.1 kB/s eta 0:00:04\n",
      "     ------------- -------------------------- 1.0/3.0 MB 642.4 kB/s eta 0:00:04\n",
      "     -------------- ------------------------- 1.0/3.0 MB 642.8 kB/s eta 0:00:03\n",
      "     -------------- ------------------------- 1.1/3.0 MB 637.3 kB/s eta 0:00:03\n",
      "     -------------- ------------------------- 1.1/3.0 MB 637.8 kB/s eta 0:00:03\n",
      "     --------------- ------------------------ 1.1/3.0 MB 637.8 kB/s eta 0:00:03\n",
      "     --------------- ------------------------ 1.2/3.0 MB 632.9 kB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 1.2/3.0 MB 633.5 kB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 1.2/3.0 MB 633.9 kB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 1.2/3.0 MB 634.4 kB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 1.3/3.0 MB 629.8 kB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 1.3/3.0 MB 635.6 kB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 1.3/3.0 MB 626.2 kB/s eta 0:00:03\n",
      "     ------------------ --------------------- 1.3/3.0 MB 631.2 kB/s eta 0:00:03\n",
      "     ------------------ --------------------- 1.3/3.0 MB 631.2 kB/s eta 0:00:03\n",
      "     ------------------ --------------------- 1.3/3.0 MB 631.2 kB/s eta 0:00:03\n",
      "     ------------------- -------------------- 1.4/3.0 MB 628.4 kB/s eta 0:00:03\n",
      "     ------------------- -------------------- 1.5/3.0 MB 629.0 kB/s eta 0:00:03\n",
      "     -------------------- ------------------- 1.5/3.0 MB 625.1 kB/s eta 0:00:03\n",
      "     -------------------- ------------------- 1.5/3.0 MB 621.8 kB/s eta 0:00:03\n",
      "     -------------------- ------------------- 1.5/3.0 MB 622.0 kB/s eta 0:00:03\n",
      "     --------------------- ------------------ 1.6/3.0 MB 618.9 kB/s eta 0:00:03\n",
      "     --------------------- ------------------ 1.6/3.0 MB 619.4 kB/s eta 0:00:03\n",
      "     --------------------- ------------------ 1.6/3.0 MB 615.7 kB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 1.6/3.0 MB 620.3 kB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 1.7/3.0 MB 617.4 kB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 1.7/3.0 MB 614.4 kB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 1.7/3.0 MB 614.9 kB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 1.8/3.0 MB 615.6 kB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 1.8/3.0 MB 612.5 kB/s eta 0:00:02\n",
      "     ------------------------ --------------- 1.8/3.0 MB 613.5 kB/s eta 0:00:02\n",
      "     ------------------------ --------------- 1.8/3.0 MB 614.1 kB/s eta 0:00:02\n",
      "     ------------------------ --------------- 1.8/3.0 MB 611.0 kB/s eta 0:00:02\n",
      "     ------------------------- -------------- 1.9/3.0 MB 615.2 kB/s eta 0:00:02\n",
      "     ------------------------- -------------- 1.9/3.0 MB 612.6 kB/s eta 0:00:02\n",
      "     -------------------------- ------------- 1.9/3.0 MB 613.2 kB/s eta 0:00:02\n",
      "     -------------------------- ------------- 2.0/3.0 MB 613.8 kB/s eta 0:00:02\n",
      "     --------------------------- ------------ 2.0/3.0 MB 614.3 kB/s eta 0:00:02\n",
      "     --------------------------- ------------ 2.0/3.0 MB 612.0 kB/s eta 0:00:02\n",
      "     --------------------------- ------------ 2.1/3.0 MB 612.6 kB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 2.1/3.0 MB 613.2 kB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 2.1/3.0 MB 613.6 kB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 2.1/3.0 MB 614.2 kB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 2.2/3.0 MB 611.9 kB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 2.2/3.0 MB 612.3 kB/s eta 0:00:02\n",
      "     ------------------------------ --------- 2.2/3.0 MB 612.9 kB/s eta 0:00:02\n",
      "     ------------------------------ --------- 2.3/3.0 MB 613.4 kB/s eta 0:00:02\n",
      "     ------------------------------ --------- 2.3/3.0 MB 613.9 kB/s eta 0:00:02\n",
      "     ------------------------------- -------- 2.3/3.0 MB 612.0 kB/s eta 0:00:02\n",
      "     ------------------------------- -------- 2.4/3.0 MB 615.2 kB/s eta 0:00:01\n",
      "     -------------------------------- ------- 2.4/3.0 MB 615.3 kB/s eta 0:00:01\n",
      "     -------------------------------- ------- 2.4/3.0 MB 613.3 kB/s eta 0:00:01\n",
      "     --------------------------------- ------ 2.4/3.0 MB 616.4 kB/s eta 0:00:01\n",
      "     --------------------------------- ------ 2.5/3.0 MB 616.9 kB/s eta 0:00:01\n",
      "     --------------------------------- ------ 2.5/3.0 MB 617.3 kB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 2.5/3.0 MB 615.5 kB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 2.6/3.0 MB 615.9 kB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 2.6/3.0 MB 616.2 kB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 2.6/3.0 MB 618.8 kB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 2.6/3.0 MB 617.0 kB/s eta 0:00:01\n",
      "     ------------------------------------ --- 2.7/3.0 MB 619.8 kB/s eta 0:00:01\n",
      "     ------------------------------------ --- 2.7/3.0 MB 617.9 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 2.7/3.0 MB 618.4 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 2.8/3.0 MB 618.6 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 2.8/3.0 MB 616.9 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 2.8/3.0 MB 616.9 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 2.8/3.0 MB 616.9 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 2.8/3.0 MB 616.9 kB/s eta 0:00:01\n",
      "     ---------------------------------------  2.9/3.0 MB 613.9 kB/s eta 0:00:01\n",
      "     ---------------------------------------  2.9/3.0 MB 614.2 kB/s eta 0:00:01\n",
      "     ---------------------------------------  2.9/3.0 MB 612.6 kB/s eta 0:00:01\n",
      "     ---------------------------------------  2.9/3.0 MB 610.7 kB/s eta 0:00:01\n",
      "     ---------------------------------------  2.9/3.0 MB 610.7 kB/s eta 0:00:01\n",
      "     ---------------------------------------  2.9/3.0 MB 610.7 kB/s eta 0:00:01\n",
      "     ---------------------------------------  2.9/3.0 MB 610.7 kB/s eta 0:00:01\n",
      "     ---------------------------------------  2.9/3.0 MB 610.7 kB/s eta 0:00:01\n",
      "     ---------------------------------------  2.9/3.0 MB 610.7 kB/s eta 0:00:01\n",
      "     ---------------------------------------  2.9/3.0 MB 610.7 kB/s eta 0:00:01\n",
      "     ---------------------------------------  2.9/3.0 MB 610.7 kB/s eta 0:00:01\n",
      "     ---------------------------------------  2.9/3.0 MB 610.7 kB/s eta 0:00:01\n",
      "     ---------------------------------------  2.9/3.0 MB 610.7 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.0/3.0 MB 559.1 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Collecting html5lib>=1.1 (from yfinance)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Collecting webencodings (from html5lib>=1.1->yfinance)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (2024.6.2)\n",
      "Downloading yfinance-0.2.40-py2.py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 10.2/73.5 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 30.7/73.5 kB 660.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 61.4/73.5 kB 469.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 71.7/73.5 kB 491.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 71.7/73.5 kB 491.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 73.5/73.5 kB 270.5 kB/s eta 0:00:00\n",
      "Downloading frozendict-2.4.4-py312-none-any.whl (16 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "   ---------------------------------------- 0.0/112.2 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/112.2 kB ? eta -:--:--\n",
      "   -------------- ------------------------ 41.0/112.2 kB 487.6 kB/s eta 0:00:01\n",
      "   --------------------- ----------------- 61.4/112.2 kB 544.7 kB/s eta 0:00:01\n",
      "   -------------------------------- ------ 92.2/112.2 kB 525.1 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 102.4/112.2 kB 490.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 102.4/112.2 kB 490.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 112.2/112.2 kB 383.2 kB/s eta 0:00:00\n",
      "Using cached lxml-5.2.2-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (pyproject.toml): started\n",
      "  Building wheel for peewee (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for peewee: filename=peewee-3.17.6-py3-none-any.whl size=138937 sha256=12d2435483724f49117205f1e3a62836e7c8b8053c8574689eeb5b59cc1afc89\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\a6\\5e\\0f\\8319805c4115320e0d3e8fb5799b114a2e4c4a3d6c7e523b06\n",
      "Successfully built peewee\n",
      "Installing collected packages: webencodings, peewee, multitasking, lxml, html5lib, frozendict, yfinance\n",
      "Successfully installed frozendict-2.4.4 html5lib-1.1 lxml-5.2.2 multitasking-0.0.11 peewee-3.17.6 webencodings-0.5.1 yfinance-0.2.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*******************   40%%                      ]  2 of 5 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$LNKD: possibly delisted; No price data found  (1d 2015-01-01 -> 2024-07-16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  5 of 5 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "['TWTR']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n",
      "['LNKD']: YFPricesMissingError('$%ticker%: possibly delisted; No price data found  (1d 2015-01-01 -> 2024-07-16)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price        Adj Close                                         Close  \\\n",
      "Ticker            AAPL         IBM LNKD        TSLA TWTR        AAPL   \n",
      "Date                                                                   \n",
      "2015-01-02   24.402176  102.338890  NaN   14.620667  NaN   27.332500   \n",
      "2015-01-05   23.714724  100.728645  NaN   14.006000  NaN   26.562500   \n",
      "2015-01-06   23.716959   98.556320  NaN   14.085333  NaN   26.565001   \n",
      "2015-01-07   24.049513   97.912224  NaN   14.063333  NaN   26.937500   \n",
      "2015-01-08   24.973557  100.040298  NaN   14.041333  NaN   27.972500   \n",
      "...                ...         ...  ...         ...  ...         ...   \n",
      "2024-07-09  228.679993  176.479996  NaN  262.329987  NaN  228.679993   \n",
      "2024-07-10  232.979996  177.839996  NaN  263.260010  NaN  232.979996   \n",
      "2024-07-11  227.570007  178.309998  NaN  241.029999  NaN  227.570007   \n",
      "2024-07-12  230.539993  182.830002  NaN  248.229996  NaN  230.539993   \n",
      "2024-07-15  234.399994  182.880005  NaN  252.639999  NaN  234.399994   \n",
      "\n",
      "Price                                         ...        Open              \\\n",
      "Ticker             IBM LNKD        TSLA TWTR  ...        AAPL         IBM   \n",
      "Date                                          ...                           \n",
      "2015-01-02  154.933075  NaN   14.620667  NaN  ...   27.847500  154.216064   \n",
      "2015-01-05  152.495224  NaN   14.006000  NaN  ...   27.072500  154.177826   \n",
      "2015-01-06  149.206497  NaN   14.085333  NaN  ...   26.635000  152.648178   \n",
      "2015-01-07  148.231354  NaN   14.063333  NaN  ...   26.799999  150.286804   \n",
      "2015-01-08  151.453156  NaN   14.041333  NaN  ...   27.307501  149.369019   \n",
      "...                ...  ...         ...  ...  ...         ...         ...   \n",
      "2024-07-09  176.479996  NaN  262.329987  NaN  ...  227.929993  177.600006   \n",
      "2024-07-10  177.839996  NaN  263.260010  NaN  ...  229.300003  176.600006   \n",
      "2024-07-11  178.309998  NaN  241.029999  NaN  ...  231.389999  177.649994   \n",
      "2024-07-12  182.830002  NaN  248.229996  NaN  ...  228.919998  178.559998   \n",
      "2024-07-15  182.880005  NaN  252.639999  NaN  ...  236.531998  183.380005   \n",
      "\n",
      "Price                                Volume                                \n",
      "Ticker     LNKD        TSLA TWTR       AAPL      IBM LNKD       TSLA TWTR  \n",
      "Date                                                                       \n",
      "2015-01-02  NaN   14.858000  NaN  212818400  5779673  NaN   71466000  NaN  \n",
      "2015-01-05  NaN   14.303333  NaN  257142000  5104898  NaN   80527500  NaN  \n",
      "2015-01-06  NaN   14.004000  NaN  263188400  6429448  NaN   93928500  NaN  \n",
      "2015-01-07  NaN   14.223333  NaN  160423600  4918083  NaN   44526000  NaN  \n",
      "2015-01-08  NaN   14.187333  NaN  237458000  4431693  NaN   51637500  NaN  \n",
      "...         ...         ...  ...        ...      ...  ...        ...  ...  \n",
      "2024-07-09  NaN  251.000000  NaN   48076100  2512700  NaN  160210900  NaN  \n",
      "2024-07-10  NaN  262.799988  NaN   62627700  3462200  NaN  128519400  NaN  \n",
      "2024-07-11  NaN  263.299988  NaN   64710600  2806800  NaN  221707300  NaN  \n",
      "2024-07-12  NaN  235.800003  NaN   53008200  4784500  NaN  155694400  NaN  \n",
      "2024-07-15  NaN  255.964996  NaN   58409071  2913279  NaN  142831728  NaN  \n",
      "\n",
      "[2398 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "stocks = ['AAPL', 'TSLA', 'TWTR', 'IBM', 'LNKD']\n",
    "\n",
    "# Define the time range\n",
    "start = '2015-01-01'\n",
    "end = pd.Timestamp.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Fetch the stock data\n",
    "df = yf.download(stocks, start=start, end=end)\n",
    "\n",
    "# Display the data\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5. What is the type of structure of df ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*******************   40%%                      ]  2 of 5 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$LNKD: possibly delisted; No price data found  (1d 2015-01-01 -> 2024-07-16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  5 of 5 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "['TWTR']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n",
      "['LNKD']: YFPricesMissingError('$%ticker%: possibly delisted; No price data found  (1d 2015-01-01 -> 2024-07-16)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the stock symbols\n",
    "stocks = ['AAPL', 'TSLA', 'TWTR', 'IBM', 'LNKD']\n",
    "\n",
    "# Define the time range\n",
    "start = '2015-01-01'\n",
    "end = pd.Timestamp.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Fetch the stock data\n",
    "df = yf.download(stocks, start=start, end=end)\n",
    "\n",
    "# Determine the type of the structure of df\n",
    "print(type(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6. Print all the Items axis values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                       0%%                      ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$LNKD: possibly delisted; No price data found  (1d 2015-01-01 -> 2024-07-16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  5 of 5 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "['LNKD']: YFPricesMissingError('$%ticker%: possibly delisted; No price data found  (1d 2015-01-01 -> 2024-07-16)')\n",
      "['TWTR']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([('Adj Close', 'AAPL'),\n",
      "            ('Adj Close',  'IBM'),\n",
      "            ('Adj Close', 'LNKD'),\n",
      "            ('Adj Close', 'TSLA'),\n",
      "            ('Adj Close', 'TWTR'),\n",
      "            (    'Close', 'AAPL'),\n",
      "            (    'Close',  'IBM'),\n",
      "            (    'Close', 'LNKD'),\n",
      "            (    'Close', 'TSLA'),\n",
      "            (    'Close', 'TWTR'),\n",
      "            (     'High', 'AAPL'),\n",
      "            (     'High',  'IBM'),\n",
      "            (     'High', 'LNKD'),\n",
      "            (     'High', 'TSLA'),\n",
      "            (     'High', 'TWTR'),\n",
      "            (      'Low', 'AAPL'),\n",
      "            (      'Low',  'IBM'),\n",
      "            (      'Low', 'LNKD'),\n",
      "            (      'Low', 'TSLA'),\n",
      "            (      'Low', 'TWTR'),\n",
      "            (     'Open', 'AAPL'),\n",
      "            (     'Open',  'IBM'),\n",
      "            (     'Open', 'LNKD'),\n",
      "            (     'Open', 'TSLA'),\n",
      "            (     'Open', 'TWTR'),\n",
      "            (   'Volume', 'AAPL'),\n",
      "            (   'Volume',  'IBM'),\n",
      "            (   'Volume', 'LNKD'),\n",
      "            (   'Volume', 'TSLA'),\n",
      "            (   'Volume', 'TWTR')],\n",
      "           names=['Price', 'Ticker'])\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the stock symbols\n",
    "stocks = ['AAPL', 'TSLA', 'TWTR', 'IBM', 'LNKD']\n",
    "\n",
    "# Define the time range\n",
    "start = '2015-01-01'\n",
    "end = pd.Timestamp.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Fetch the stock data\n",
    "df = yf.download(stocks, start=start, end=end)\n",
    "\n",
    "# Print all the Items axis values\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7. Good, now we know the data avaiable. Create a dataFrame called vol, with the Volume values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*******************   40%%                      ]  2 of 5 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$LNKD: possibly delisted; No price data found  (1d 2015-01-01 -> 2024-07-16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  5 of 5 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "['LNKD']: YFPricesMissingError('$%ticker%: possibly delisted; No price data found  (1d 2015-01-01 -> 2024-07-16)')\n",
      "['TWTR']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker           AAPL      IBM  LNKD      TSLA  TWTR\n",
      "Date                                                \n",
      "2015-01-02  212818400  5779673   NaN  71466000   NaN\n",
      "2015-01-05  257142000  5104898   NaN  80527500   NaN\n",
      "2015-01-06  263188400  6429448   NaN  93928500   NaN\n",
      "2015-01-07  160423600  4918083   NaN  44526000   NaN\n",
      "2015-01-08  237458000  4431693   NaN  51637500   NaN\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the stock symbols\n",
    "stocks = ['AAPL', 'TSLA', 'TWTR', 'IBM', 'LNKD']\n",
    "\n",
    "# Define the time range\n",
    "start = '2015-01-01'\n",
    "end = pd.Timestamp.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Fetch the stock data\n",
    "df = yf.download(stocks, start=start, end=end)\n",
    "\n",
    "# Create a DataFrame with the Volume values\n",
    "vol = df['Volume']\n",
    "\n",
    "# Print the first few rows of the volume DataFrame\n",
    "print(vol.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8. Aggregate the data of Volume to weekly\n",
    "Hint: Be careful to not sum data from the same week of 2015 and other years.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker            AAPL       IBM  LNKD       TSLA  TWTR\n",
      "Date                                                   \n",
      "2015-01-04   212818400   5779673   0.0   71466000   0.0\n",
      "2015-01-11  1133010000  25578884   0.0  340644000   0.0\n",
      "2015-01-18  1216906400  24329751   0.0  461988000   0.0\n",
      "2015-01-25   794948000  32682062   0.0  243175500   0.0\n",
      "2015-02-01  1863370800  34442689   0.0  235803000   0.0\n"
     ]
    }
   ],
   "source": [
    "# Resample the data to weekly frequency, summing the volume for each week\n",
    "vol_weekly = vol.resample('W').sum()\n",
    "\n",
    "# Print the first few rows of the weekly volume DataFrame\n",
    "print(vol_weekly.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9. Find all the volume traded in the year of 2015\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  5 of 5 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "['LNKD']: YFPricesMissingError('$%ticker%: possibly delisted; No price data found  (1d 2015-01-01 -> 2024-07-16)')\n",
      "['TWTR']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$LNKD: possibly delisted; No price data found  (1d 2015-01-01 -> 2024-07-16)\n",
      "Total volume traded in 2015 for each stock:\n",
      "Ticker\n",
      "AAPL    5.226420e+10\n",
      "IBM     1.156439e+09\n",
      "LNKD    0.000000e+00\n",
      "TSLA    1.632327e+10\n",
      "TWTR    0.000000e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Define the time range\n",
    "start = \"2015-01-01\"\n",
    "end = pd.to_datetime(\"today\").strftime('%Y-%m-%d')\n",
    "\n",
    "# Select the stock symbols\n",
    "stocks = [\"AAPL\", \"TSLA\", \"TWTR\", \"IBM\", \"LNKD\"]\n",
    "\n",
    "# Fetch the data from Yahoo Finance\n",
    "df = yf.download(stocks, start=start, end=end)\n",
    "\n",
    "# Extract the Volume data\n",
    "vol = df['Volume']\n",
    "\n",
    "# Convert the index to DateTime if not already\n",
    "vol.index = pd.to_datetime(vol.index)\n",
    "\n",
    "# Filter the data for the year 2015\n",
    "vol_2015 = vol[vol.index.year == 2015]\n",
    "\n",
    "# Sum the volume traded in 2015\n",
    "total_volume_2015 = vol_2015.sum()\n",
    "\n",
    "print(\"Total volume traded in 2015 for each stock:\")\n",
    "print(total_volume_2015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##DELETING (IRIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.1,3.5,1.4,0.2,Iris-setosa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9,3.0,1.4,0.2,Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7,3.2,1.3,0.2,Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6,3.1,1.5,0.2,Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0,3.6,1.4,0.2,Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4,3.9,1.7,0.4,Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.6,3.4,1.4,0.3,Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0,3.4,1.5,0.2,Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.4,2.9,1.4,0.2,Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.9,3.1,1.5,0.1,Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.4,3.7,1.5,0.2,Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5.1,3.5,1.4,0.2,Iris-setosa\n",
       "0  4.9,3.0,1.4,0.2,Iris-setosa\n",
       "1  4.7,3.2,1.3,0.2,Iris-setosa\n",
       "2  4.6,3.1,1.5,0.2,Iris-setosa\n",
       "3  5.0,3.6,1.4,0.2,Iris-setosa\n",
       "4  5.4,3.9,1.7,0.4,Iris-setosa\n",
       "5  4.6,3.4,1.4,0.3,Iris-setosa\n",
       "6  5.0,3.4,1.5,0.2,Iris-setosa\n",
       "7  4.4,2.9,1.4,0.2,Iris-setosa\n",
       "8  4.9,3.1,1.5,0.1,Iris-setosa\n",
       "9  5.4,3.7,1.5,0.2,Iris-setosa"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url =\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "iris = pd.read_csv(url, delimiter='\\t')\n",
    "iris.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Create columns for the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth      Species\n",
      "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
      "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
      "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
      "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
      "4          5.0         3.6          1.4         0.2  Iris-setosa\n",
      "5          5.4         3.9          1.7         0.4  Iris-setosa\n",
      "6          4.6         3.4          1.4         0.3  Iris-setosa\n",
      "7          5.0         3.4          1.5         0.2  Iris-setosa\n",
      "8          4.4         2.9          1.4         0.2  Iris-setosa\n",
      "9          4.9         3.1          1.5         0.1  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Raw data in text format\n",
    "data = \"\"\"5.1,3.5,1.4,0.2,Iris-setosa\n",
    "4.9,3.0,1.4,0.2,Iris-setosa\n",
    "4.7,3.2,1.3,0.2,Iris-setosa\n",
    "4.6,3.1,1.5,0.2,Iris-setosa\n",
    "5.0,3.6,1.4,0.2,Iris-setosa\n",
    "5.4,3.9,1.7,0.4,Iris-setosa\n",
    "4.6,3.4,1.4,0.3,Iris-setosa\n",
    "5.0,3.4,1.5,0.2,Iris-setosa\n",
    "4.4,2.9,1.4,0.2,Iris-setosa\n",
    "4.9,3.1,1.5,0.1,Iris-setosa\n",
    "5.4,3.7,1.5,0.2,Iris-setosa\"\"\"\n",
    "\n",
    "# Converting the data into a DataFrame with defined columns\n",
    "data_io = StringIO(data)\n",
    "columns = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "iris = pd.read_csv(data_io, header=None, names=columns)\n",
    "\n",
    "# Displaying the DataFrame with columns\n",
    "print(iris.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5. Is there any missing value in the dataframe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the dataframe:\n",
      " SepalLength    0\n",
      "SepalWidth     0\n",
      "PetalLength    0\n",
      "PetalWidth     0\n",
      "Species        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "missing_values = iris.isnull().sum()\n",
    "\n",
    "# Print the result\n",
    "print(\"Missing values in the dataframe:\\n\", missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6. Lets set the values of the rows 10 to 29 of the column 'petal_length' to NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    petal_length\n",
      "10           NaN\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries and setting up the DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'iris' DataFrame is already defined as per previous steps\n",
    "\n",
    "# Set rows 10 to 29 of 'petal_length' to NaN\n",
    "iris.loc[10:29, 'petal_length'] = np.nan\n",
    "\n",
    "# Verify the changes\n",
    "print(iris.loc[10:29, ['petal_length']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7. Good, now lets substitute the NaN values to 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    petal_length\n",
      "10           1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_9576\\125664809.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  iris['petal_length'].fillna(1.0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'iris' DataFrame is already defined and NaN values are set in 'petal_length'\n",
    "\n",
    "# Substitute NaN values in 'petal_length' with 1.0\n",
    "iris['petal_length'].fillna(1.0, inplace=True)\n",
    "\n",
    "# Verify the changes\n",
    "print(iris.loc[10:29, ['petal_length']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8. Now let's delete the column class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['species'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming 'iris' DataFrame is already defined\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Delete the 'class' column\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43miris\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspecies\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Verify the changes\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(iris\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['species'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Assuming 'iris' DataFrame is already defined\n",
    "\n",
    "# Delete the 'class' column\n",
    "iris.drop(columns=['species'], inplace=True)\n",
    "\n",
    "# Verify the changes\n",
    "print(iris.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9. Set the first 3 rows as NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth      Species  petal_length\n",
      "0          NaN         NaN          NaN         NaN          NaN           NaN\n",
      "1          NaN         NaN          NaN         NaN          NaN           NaN\n",
      "2          NaN         NaN          NaN         NaN          NaN           NaN\n",
      "3          4.6         3.1          1.5         0.2  Iris-setosa           1.0\n",
      "4          5.0         3.6          1.4         0.2  Iris-setosa           1.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'iris' DataFrame is already defined\n",
    "\n",
    "# Set the first 3 rows as NaN for all columns\n",
    "iris.iloc[:3, :] = np.nan\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(iris.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 10. Delete the rows that have NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth      Species  petal_length\n",
      "3          4.6         3.1          1.5         0.2  Iris-setosa           1.0\n",
      "4          5.0         3.6          1.4         0.2  Iris-setosa           1.0\n",
      "5          5.4         3.9          1.7         0.4  Iris-setosa           1.0\n",
      "6          4.6         3.4          1.4         0.3  Iris-setosa           1.0\n",
      "7          5.0         3.4          1.5         0.2  Iris-setosa           1.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'iris' DataFrame is already defined\n",
    "\n",
    "# Drop rows with NaN values\n",
    "iris = iris.dropna()\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(iris.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth      Species  petal_length\n",
      "0          4.6         3.1          1.5         0.2  Iris-setosa           1.0\n",
      "1          5.0         3.6          1.4         0.2  Iris-setosa           1.0\n",
      "2          5.4         3.9          1.7         0.4  Iris-setosa           1.0\n",
      "3          4.6         3.4          1.4         0.3  Iris-setosa           1.0\n",
      "4          5.0         3.4          1.5         0.2  Iris-setosa           1.0\n"
     ]
    }
   ],
   "source": [
    "iris = iris.dropna(how='all')\n",
    "print(iris.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 11. Reset the index so it begins with 0 again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth      Species  petal_length\n",
      "0          4.6         3.1          1.5         0.2  Iris-setosa           1.0\n",
      "1          5.0         3.6          1.4         0.2  Iris-setosa           1.0\n",
      "2          5.4         3.9          1.7         0.4  Iris-setosa           1.0\n",
      "3          4.6         3.4          1.4         0.3  Iris-setosa           1.0\n",
      "4          5.0         3.4          1.5         0.2  Iris-setosa           1.0\n"
     ]
    }
   ],
   "source": [
    "# Reset index\n",
    "iris = iris.reset_index(drop=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(iris.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
